{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a11220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: w = 0.8118, b = 0.7605, Loss = 0.1623\n",
      "Iteration 2: w = 0.8119, b = 0.7607, Loss = 0.1623\n",
      "Iteration 3: w = 0.8120, b = 0.7608, Loss = 0.1623\n",
      "Iteration 4: w = 0.8121, b = 0.7609, Loss = 0.1623\n",
      "Iteration 5: w = 0.8122, b = 0.7610, Loss = 0.1623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid and tanh functions and their derivatives\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "def tanh_derivative(z):\n",
    "    return 1 - tanh(z)**2\n",
    "\n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "# Loss function\n",
    "def loss(y, f_x):\n",
    "    return -y * np.log(f_x)\n",
    "\n",
    "# Gradient descent update rule\n",
    "def gradient_descent_update(x, y, w, b, learning_rate):\n",
    "    # Forward pass\n",
    "    z = (1 + tanh(w * x + b)) / 2\n",
    "    f_x = sigmoid(z)\n",
    "    \n",
    "    # Compute the loss\n",
    "    L = loss(y, f_x)\n",
    "    \n",
    "    # Compute gradients using the chain rule\n",
    "    dL_df = -y / f_x\n",
    "    df_dz = sigmoid_derivative(z)\n",
    "    dz_dw = (1 / 2) * tanh_derivative(w * x + b) * x\n",
    "    dz_db = (1 / 2) * tanh_derivative(w * x + b)\n",
    "    \n",
    "    # Partial derivatives of L with respect to w and b\n",
    "    dL_dw = dL_df * df_dz * dz_dw\n",
    "    dL_db = dL_df * df_dz * dz_db\n",
    "    \n",
    "    # Update weights and bias\n",
    "    w -= learning_rate * dL_dw\n",
    "    b -= learning_rate * dL_db\n",
    "    \n",
    "    return w, b, L\n",
    "\n",
    "# Initialize parameters\n",
    "w = np.random.randn()  # random initial weight\n",
    "b = np.random.randn()  # random initial bias\n",
    "learning_rate = 0.01\n",
    "x = 1  # input value\n",
    "y = 0.5  # target output\n",
    "\n",
    "# Run gradient descent for 5 iterations\n",
    "for i in range(5):\n",
    "    w, b, L = gradient_descent_update(x, y, w, b, learning_rate)\n",
    "    print(f\"Iteration {i + 1}: w = {w:.4f}, b = {b:.4f}, Loss = {L:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e8e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output E: 0.6370\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the activation functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "# Inputs (constants)\n",
    "u = 1.0  # Example value\n",
    "v = 2.0  # Example value\n",
    "w = 3.0  # Example value\n",
    "x = 4.0  # Example value\n",
    "\n",
    "# Parameters (variables to be adjusted)\n",
    "a = 0.5  # Example initial value for a\n",
    "b = 0.5  # Example initial value for b\n",
    "c = 0.5  # Example initial value for c\n",
    "d = 0.5  # Example initial value for d\n",
    "\n",
    "# Compute the input to f() and g()\n",
    "z_f = a * u + b * v\n",
    "z_g = c * w + d * x\n",
    "\n",
    "# Apply activation functions\n",
    "f_output = sigmoid(z_f)\n",
    "g_output = tanh(z_g)\n",
    "\n",
    "# Compute E using the given formula\n",
    "E = 2 * f_output - g_output\n",
    "\n",
    "# Print the output\n",
    "print(f\"Output E: {E:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25edc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the NN: 0.7050724231652905\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define trigonometric functions\n",
    "def sec(x):\n",
    "    return 1 / np.cos(x)\n",
    "\n",
    "# Forward pass function\n",
    "def forward_pass(x, weights):\n",
    "    # Extract weights\n",
    "    W1, W2, W3, W4, W5, W6, W7, W8 = weights\n",
    "\n",
    "    # Compute outputs at each stage\n",
    "    S1 = np.tan(W1 * x)          # Output after tan\n",
    "    S2 = sec(W2 * x + W3 * S1)    # Output after sec\n",
    "    S3 = np.sin(W4 * S2)          # Output after sin\n",
    "    S4 = np.cos(W6 * S3 + W5 * S3)  # Output after cos\n",
    "    y = np.tanh(W7 * S4 + W8 * S3) # Output after tanh, which is the final output\n",
    "    \n",
    "    return y\n",
    "\n",
    "# Example usage\n",
    "x = 1.0  # Example input\n",
    "weights = [0.5, 0.3, 0.8, 0.2, 1.0, 0.6, 0.7, 0.9]  # Example weights, replace with actual values if known\n",
    "\n",
    "# Perform forward pass\n",
    "output = forward_pass(x, weights)\n",
    "print(\"Output of the NN:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0f7ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the ANN: 2.06115369216775e-09\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Forward pass function\n",
    "def forward_pass(x):\n",
    "    # Calculate h11 and h12 based on the given equations\n",
    "    h11 = sigmoid(500 * x + 30)\n",
    "    h12 = sigmoid(500 * x - 30)\n",
    "    \n",
    "    # Calculate h21 by subtracting h12 from h11\n",
    "    h21 = h11 - h12\n",
    "    \n",
    "    return h21\n",
    "\n",
    "# Example usage\n",
    "x = 0.1  # Example input, you can change this value\n",
    "output = forward_pass(x)\n",
    "print(\"Output of the ANN:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf5d8491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output f(x1, x2): 1.9151695967140057e-174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the neural network structure based on the given equations\n",
    "def neural_network(x1, x2):\n",
    "    # First layer calculations (h11, h12, h13, h14)\n",
    "    h11 = sigmoid(-(x1 + 50 * x2 + 100))\n",
    "    h12 = sigmoid(-(x1 + 50 * x2 - 100))\n",
    "    h13 = sigmoid(-(50 * x1 + x2 + 100))\n",
    "    h14 = sigmoid(-(50 * x1 + x2 - 100))\n",
    "\n",
    "    # Second layer calculations (h21, h22)\n",
    "    h21 = h11 - h12\n",
    "    h22 = h13 - h14\n",
    "\n",
    "    # Third layer calculation (h31)\n",
    "    h31 = h21 + h22\n",
    "\n",
    "    # Final output layer calculation (f)\n",
    "    f = sigmoid(100 * h31 - 200)\n",
    "\n",
    "    return f\n",
    "\n",
    "# Example input values\n",
    "x1 = 0.5  # Replace with any value for x1\n",
    "x2 = -0.5  # Replace with any value for x2\n",
    "\n",
    "# Calculate the output of the network\n",
    "output = neural_network(x1, x2)\n",
    "print(f\"Output f(x1, x2): {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad846af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
