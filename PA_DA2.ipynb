{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e43b8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 9.8634 - mae: 3.0902 - val_loss: 6.8366 - val_mae: 2.5545\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.5083 - mae: 2.2648 - val_loss: 2.9258 - val_mae: 1.5665\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0787 - mae: 1.2617 - val_loss: 1.0871 - val_mae: 0.8193\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.8927 - mae: 0.7614 - val_loss: 0.8678 - val_mae: 0.7259\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7940 - mae: 0.7222 - val_loss: 0.8055 - val_mae: 0.7060\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7845 - mae: 0.7142 - val_loss: 0.7453 - val_mae: 0.6790\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7291 - mae: 0.6910 - val_loss: 0.6949 - val_mae: 0.6541\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7151 - mae: 0.6793 - val_loss: 0.6497 - val_mae: 0.6308\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5971 - mae: 0.6213 - val_loss: 0.6071 - val_mae: 0.6083\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6052 - mae: 0.6316 - val_loss: 0.5510 - val_mae: 0.5799\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017126DD9EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "MLP Model MAE (Distance Prediction): 0.5799071316724315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshni\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 5541.1162 - mae: 73.8096 - val_loss: 5592.8442 - val_mae: 74.1073\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5608.3135 - mae: 74.1771 - val_loss: 5552.8193 - val_mae: 73.8442\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5530.8481 - mae: 73.7122 - val_loss: 5474.3936 - val_mae: 73.3320\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5407.4258 - mae: 72.9305 - val_loss: 5306.2119 - val_mae: 72.2302\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5199.0508 - mae: 71.4966 - val_loss: 4987.5708 - val_mae: 70.0863\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4806.3110 - mae: 68.8231 - val_loss: 4476.1152 - val_mae: 66.4591\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4160.9878 - mae: 64.0777 - val_loss: 3774.9453 - val_mae: 61.0356\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3441.9512 - mae: 58.2023 - val_loss: 2924.9175 - val_mae: 53.6143\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2535.4170 - mae: 49.6586 - val_loss: 2053.9719 - val_mae: 44.5533\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1723.4996 - mae: 40.4090 - val_loss: 1280.6904 - val_mae: 34.5707\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001713D924360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step\n",
      "Bi-LSTM Model MAE (Heart Rate Prediction): 34.570683367604666\n",
      "Anonymized Data Sample:\n",
      "   Heart_Rate     Speed  Distance  Calories_Burned  Time_Spent\n",
      "0          83  6.149760  2.867288       232.691498   58.838744\n",
      "1          77  6.425137  2.215889       303.753286   69.927776\n",
      "2          63  4.302075  3.598500       291.554503   59.300853\n",
      "3          81  6.374710  2.430204       238.492928   65.042158\n",
      "4          60  5.660476  3.090425       242.463090   49.702807\n",
      "Noisy Data Sample:\n",
      "   Heart_Rate     Speed  Distance  Calories_Burned  Time_Spent\n",
      "0          83  6.149760  2.867288       232.736625   58.838744\n",
      "1          77  6.425137  2.215889       301.858389   69.927776\n",
      "2          63  4.302075  3.598500       286.548108   59.300853\n",
      "3          81  6.374710  2.430204       234.977904   65.042158\n",
      "4          60  5.660476  3.090425       246.584052   49.702807\n"
     ]
    }
   ],
   "source": [
    "#ROSHNI JOSHI- 21BDS0338\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "\n",
    "# 1. Load dataset (replace with actual dataset path)\n",
    "\n",
    "data = {\n",
    "    'Heart_Rate': np.random.normal(75, 10, 1000),  # Simulated heart rate\n",
    "    'Speed': np.random.normal(5, 1, 1000),         # Simulated speed in km/h\n",
    "    'Distance': np.random.normal(3, 0.5, 1000),    # Simulated distance in km\n",
    "    'Calories_Burned': np.random.normal(300, 50, 1000),  # Calories burned\n",
    "    'Time_Spent': np.random.normal(60, 10, 1000),       # Time spent in minutes\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "features = df[['Heart_Rate', 'Speed', 'Calories_Burned', 'Time_Spent']]\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split dataset for training and testing\n",
    "X = features_scaled\n",
    "y_distance = df['Distance']  # Target for MLP model\n",
    "y_heart_rate = df['Heart_Rate']  # Target for Bi-LSTM\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_distance, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Model Implementation\n",
    "\n",
    "## MLP Model for Distance Prediction\n",
    "mlp_model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Predicting distance\n",
    "])\n",
    "\n",
    "mlp_model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions using the MLP model\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# Evaluate the MLP model\n",
    "mlp_mae = mean_absolute_error(y_test, y_pred_mlp)\n",
    "print(f\"MLP Model MAE (Distance Prediction): {mlp_mae}\")\n",
    "\n",
    "## Bi-LSTM for Sequence Prediction (e.g., Heart Rate)\n",
    "# For sequence data, we need to reshape the input into a 3D array (samples, time steps, features)\n",
    "X_seq = np.array(features_scaled)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], 1, X_seq.shape[1]))  # Reshape to (samples, time steps, features)\n",
    "\n",
    "# Train-test split for Bi-LSTM\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq, y_heart_rate, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bi-LSTM Model\n",
    "bi_lstm_model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=False), input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Predicting heart rate\n",
    "])\n",
    "\n",
    "bi_lstm_model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the Bi-LSTM model\n",
    "bi_lstm_model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
    "\n",
    "# Make predictions using the Bi-LSTM model\n",
    "y_pred_lstm = bi_lstm_model.predict(X_test_seq)\n",
    "\n",
    "# Evaluate the Bi-LSTM model\n",
    "lstm_mae = mean_absolute_error(y_test_seq, y_pred_lstm)\n",
    "print(f\"Bi-LSTM Model MAE (Heart Rate Prediction): {lstm_mae}\")\n",
    "\n",
    "# 4. Privacy Features (Anonymization & Pseudorandom Noise)\n",
    "def anonymize_data(df):\n",
    "    \"\"\" Anonymize data by removing user identifiers \"\"\"\n",
    "    anonymized_df = df.copy()\n",
    "    anonymized_df['Heart_Rate'] = anonymized_df['Heart_Rate'].apply(lambda x: random.randint(60, 100))\n",
    "    anonymized_df['Speed'] = anonymized_df['Speed'].apply(lambda x: random.uniform(3, 7))\n",
    "    return anonymized_df\n",
    "\n",
    "def add_noise_to_data(df):\n",
    "    \"\"\" Add pseudorandom noise to sensitive information \"\"\"\n",
    "    noisy_df = df.copy()\n",
    "    noisy_df['Calories_Burned'] = noisy_df['Calories_Burned'] + np.random.normal(0, 5, df.shape[0])  # Add noise to calories\n",
    "    return noisy_df\n",
    "\n",
    "# Apply anonymization and noise\n",
    "anonymized_data = anonymize_data(df)\n",
    "noisy_data = add_noise_to_data(anonymized_data)\n",
    "\n",
    "print(\"Anonymized Data Sample:\")\n",
    "print(anonymized_data.head())\n",
    "\n",
    "print(\"Noisy Data Sample:\")\n",
    "print(noisy_data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
